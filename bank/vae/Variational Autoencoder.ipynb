{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphical Model Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jensen's Inequality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kullback-Leibler Divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evidence Lower Bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoder in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def vae_loss(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x.view(-1, 784), x.view(-1, 784), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubPixelConv2d(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, bias=False, upscale_factor=2, use_relu=True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(input_channels, output_channels, kernel_size=3, stride=1, padding=1, bias=bias)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.use_relu = use_relu\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.pixel_shuffle(x)\n",
    "        if self.use_relu:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # encoder layers\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.mu_layer = nn.Linear(256, 20)\n",
    "        self.log_sigma_layer = nn.Linear(256, 20)\n",
    "        \n",
    "        # decoder layers\n",
    "        self.fc2 = nn.Linear(20, 256)\n",
    "        self.fc3 = nn.Linear(256, 784)\n",
    "        self.subconv1 = SubPixelConv2d(16, 32)\n",
    "        self.subconv2 = SubPixelConv2d(8, 4, use_relu=False)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        mu = self.mu_layer(x)\n",
    "        logvar = self.log_sigma_layer(x)\n",
    "        return mu, logvar\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        sigma = torch.exp(0.5 * logvar)\n",
    "        z = mu + sigma * torch.randn_like(sigma)\n",
    "        return z\n",
    "        \n",
    "    def decoder(self, z):\n",
    "        x = F.relu(self.fc2(z))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = x.view(x.size(0), 16, 7, 7)\n",
    "        x = self.subconv1(x)\n",
    "        x = self.subconv2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        out = self.decoder(z)\n",
    "        return out, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('vae')\n",
    "logger.setLevel(logging.INFO)\n",
    "handler = logging.StreamHandler()\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "if len(logger.handlers) == 0:\n",
    "    logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "lr = 1e-3\n",
    "seed = 42\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if seed:\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "vae = VAE().to(device)\n",
    "optimizer = optim.Adam(vae.parameters(), lr=lr)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "mnist = datasets.MNIST('../../pytorch-datasets', train=True, transform=transform)\n",
    "train_loader = DataLoader(mnist, batch_size=batch_size, num_workers=2, shuffle=True)\n",
    "\n",
    "# train\n",
    "logger.info('')\n",
    "logger.info('Batch Size : %d' % batch_size)\n",
    "logger.info('Number of Epochs : %d' % epochs)\n",
    "logger.info('Steps per Epoch : %d' % len(train_loader))\n",
    "logger.info('')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    vae.train()\n",
    "    mean_loss = 0\n",
    "    logger.info('============== Epoch %d/%d ==============' % (epoch + 1, epochs))\n",
    "    for step, (images, _) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        recons, mu, logvar = vae(images)\n",
    "        optimizer.zero_grad()\n",
    "        loss = vae_loss(recons, images, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            logger.info('step: %d, loss: %.5f' % (step, loss.item()))\n",
    "        mean_loss += loss.item()\n",
    "\n",
    "    logger.info('epoch : %d, average loss : %.5f' % (epoch + 1, mean_loss / len(train_loader.dataset)))\n",
    "\n",
    "    vae.eval()\n",
    "    with torch.no_grad():\n",
    "        sample = torch.randn(64, 20).to(device)\n",
    "        sample = vae.decoder(sample).cpu()\n",
    "        save_image(sample, 'results/sample_{}.png'.format(epoch))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
